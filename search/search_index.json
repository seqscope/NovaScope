{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NovaScope documantation","text":"<p>This is the documentation for the NovaScope, a pipeline to preprocess the spatial transcriptomics data from Novaseq.</p>"},{"location":"#documentation-overview","title":"Documentation Overview","text":"<p>The current documentation include the following:</p> <ul> <li>Installation:<ul> <li>Requirements: Instructions on how to install necessary software tools and obtain reference datasets.</li> <li>Environment Setup: A quick guide to set up your environment YAML file.</li> <li>Slurm: (Optional) Instructions for creating a configuration file for the SLURM scheduler.</li> </ul> </li> <li>Getting Started:<ul> <li>Preparing Input: How to ready your input data and configuration file.</li> <li>Execute NovaScope: Three options to execute the pipeline.</li> <li>Output: Details on the structure of the output directory and the usage of the produced data.</li> </ul> </li> </ul>"},{"location":"#an-overview-of-the-workflow-structure","title":"An Overview of the Workflow Structure","text":"<p>Figure 1: The overall flow and dependencies between rules. Each node in the graph represents a rule within your Snakemake workflow. Each arrow among nodes stands for the rule dependency among rules, with the direction that points from prerequisite rules to a dependent rule. The prerequisite rules must be executed before the dependent rule can start.</p>"},{"location":"getting_started/execute/","title":"Executing NovaScope Pipeline","text":""},{"location":"getting_started/execute/#1-preliminary-steps","title":"1 Preliminary Steps","text":"<p>Executing a dry run is a critical initial step. It verifies that your <code>config_job.yaml</code> is properly configured and outlines the necessary jobs to be executed. </p> <p>Additionally, you can create a rule graph that visually represents the structure of the workflow or a DAG (Directed Acyclic Graph) to view all jobs and their actual dependency structure.</p> <pre><code># Paths\nsmk_dir=\"&lt;path_to_NovaScope_repository&gt;\"    # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"&lt;job_directory&gt;\"                   # Replace &lt;job_directory&gt; with your specific job directory path, which has the `config_job.yaml` file.\n\n## (Recommended) Start with a dry run\n## - View all information:\nsnakemake -s $smk_dir/NovaScope.smk --rerun-incomplete -d $job_dir --dry-run -p\n\n## - Simply summarize the jobs to be executed without other information:\nsnakemake -s $smk_dir/NovaScope.smk --rerun-incomplete -d $job_dir --dry-run --quiet\n\n## (Optional) Visualization.\n## - (1) Rulegraph\nsnakemake --rulegraph  -s $smk_dir/NovaScope.smk --rerun-incomplete -d $job_dir | dot -Tpdf &gt; rulegraph.pdf\n\n## - (2) DAG\nsnakemake --dag  -s $smk_dir/NovaScope.smk --rerun-incomplete -d $job_dir | dot -Tpdf &gt; dag.pdf\n</code></pre>"},{"location":"getting_started/execute/#2-execution-options","title":"2 Execution Options","text":""},{"location":"getting_started/execute/#option-a-slurm-using-a-master-job","title":"Option A: SLURM using a Master Job","text":"<p>This approach involves utilizing a master SLURM job to oversee and manage the status of all other jobs. </p> <p>First, you need to establish the master job. The primary role of this job is to monitor the progress of all tasks, handle job submissions based on dependencies and available resources. Thus, it requires minimal memory but an extended time limit. Its time limit should be longer than the total time required to complete all associated jobs.</p> <p>Create a file with the information below, e.g. submit_HPC.job. See examples in the regional section, full section shallow, and full section deep test runs.</p> <pre><code>#!/bin/bash\n####  Job configuration\n#SBATCH --account=&lt;account_name&gt;               # Replace &lt;account_name&gt; with your account identifier\n#SBATCH --partition=&lt;partition_name&gt;           # Replace &lt;partition_name&gt; with your partition name\n#SBATCH --job-name=&lt;job_name&gt;                  # Replace &lt;job_name&gt; with a name for your job\n#SBATCH --nodes=1                              # Number of nodes, adjust as needed\n#SBATCH --ntasks-per-node=1                    # Number of tasks per node, adjust based on requirement\n#SBATCH --cpus-per-task=1                      # Number of CPUs per task, adjust as needed\n#SBATCH --mem-per-cpu=&lt;memory_allocation&gt;      # Memory per CPU, replace &lt;memory_allocation&gt; with value, e.g., \"2000m\"\n#SBATCH --time=&lt;time_limit&gt;                    # Job time limit, replace &lt;time_limit&gt; with value, e.g., \"72:00:00\"\n#SBATCH --mail-user=&lt;your_email&gt;               # Replace &lt;your_email&gt; with your email address\n#SBATCH --mail-type=END,FAIL,REQUEUE           # Notification types for job status\n#SBATCH --output=./logs/&lt;log_filename&gt;         # Replace &lt;log_filename&gt; with the log file name pattern\n\n# Paths\nsmk_dir=\"&lt;path_to_NovaScope_repository&gt;\"            # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"&lt;path_to_the_job_directory&gt;\"               # Replace &lt;path_to_the_job_directory&gt; with your specific job directory path\nslurm_params=\"--profile &lt;path_to_slurm_directory&gt;\"  # Replace &lt;path_to_slurm_directory&gt; with your directory of the SLURM configuration file\n\n# Execute the NovaScope pipeline\nsnakemake $slurm_params  --latency-wait 120  -s ${smk_dir}/NovaScope.smk  -d $job_dir \n</code></pre> <p>Then submit the master job:</p> <pre><code>sbatch submit_HPC.job\n</code></pre>"},{"location":"getting_started/execute/#option-b-slurm-via-command-line","title":"Option B: SLURM via Command Line","text":"<p>For a small number of quick jobs, you can submit them with a single command line. </p> <p>However, it's important to remember that if you log out before all jobs have been submitted to SLURM, any remaining jobs, i.e., those haven't been submitted, will not be submitted.</p> <pre><code>smk_dir=\"&lt;path_to_NovaScope_repository&gt;\"            # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"&lt;path_to_the_job_directory&gt;\"               # Replace &lt;path_to_the_job_directory&gt; with your specific job directory path\nslurm_params=\"--profile &lt;path_to_slurm_directory&gt;\"  # Replace &lt;path_to_slurm_directory&gt; with your directory of the SLURM configuration file\n\nsnakemake $slurm_params --latency-wait 120 -s ${smk_dir}/NovaScope.smk -d $job_dir \n</code></pre>"},{"location":"getting_started/execute/#option-c-local-execution","title":"Option C: Local Execution","text":"<p>Run the pipeline locally, with specifying the number of cores. See examples in the regional section, full section shallow, and full section deep test runs.</p> <pre><code>smk_dir=\"&lt;path_to_NovaScope_repository&gt;\"       # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"&lt;path_to_the_job_directory&gt;\"          # Replace &lt;job_directory&gt; with your specific job directory path\n\nNcores=1 # Number of CPU cores\n\nsnakemake --latency-wait 120 -s ${smk_dir}/NovaScope.smk -d $job_dir --cores $Ncores --rerun-incomplete \n</code></pre>"},{"location":"getting_started/output/","title":"Output","text":""},{"location":"getting_started/output/#1-output-directory-structure","title":"1. Output Directory Structure","text":"<p>The directory passed through <code>output</code> paramter in the <code>config_job.yaml</code> will be organized as follows, </p> <pre><code>\u251c\u2500\u2500 align\n\u251c\u2500\u2500 histology\n\u251c\u2500\u2500 seq1st\n\u2514\u2500\u2500 seq2nd\n</code></pre>"},{"location":"getting_started/output/#11-seq1st","title":"1.1 seq1st","text":"<p>The seq1st directory is structured for organizing 1st sequencing FASTQ files and spatial barcode maps. It includes:</p> <ul> <li>A fastqs subdirectory for all input 1st sequencing FASTQ files (<code>fastq</code>).</li> <li>Two subdirectories for spatial barcode maps:<ul> <li><code>sbcds</code> for maps of individual tiles from the 1st sequencing,</li> <li><code>nbcds</code> for a map organized on a per-chip basis, used in later processing.</li> </ul> </li> </ul> <pre><code>\u2514\u2500\u2500 seq1st\n    \u2514\u2500\u2500 &lt;flowcell_ID&gt;\n        \u251c\u2500\u2500 fastqs\n        \u251c\u2500\u2500 nbcds\n        \u2514\u2500\u2500 sbcds\n</code></pre>"},{"location":"getting_started/output/#12-seq2nd","title":"1.2 seq2nd","text":"<p>The seq2nd directory is dedicated to managing all input 2nd sequencing FASTQ files.</p>"},{"location":"getting_started/output/#13-histology","title":"1.3 histology","text":"<p>The <code>histology</code> directory is designated for holding all input histology files.</p>"},{"location":"getting_started/output/#14-align","title":"1.4 align","text":"<p>The <code>align</code> directory encompasses several subdirectories, including:  (1) <code>match</code>, which houses the outcomes of aligning second sequencing reads with spatial barcodes for the corresponding chip section;  (2) <code>bam</code>, where alignment outcomes such as the BAM file, summary metrics, and visualizations are stored;  (3) <code>sge</code>, containing a spatial gene expression (SGE) matrix and its associated visualizations;  (4) <code>histology</code>, which stores histology images aligned with the spatial coordinates of the SGE matrix.</p> <pre><code>align\n\u2514\u2500\u2500 &lt;flowcell_ID&gt;\n    \u2514\u2500\u2500 &lt;section_chip_ID&gt;\n     \u00a0\u00a0 \u251c\u2500\u2500 bam\n     \u00a0\u00a0 \u251c\u2500\u2500 histology\n     \u00a0\u00a0 \u251c\u2500\u2500 match\n     \u00a0\u00a0 \u2514\u2500\u2500 sge\n</code></pre>"},{"location":"getting_started/output/#2-usage","title":"2. Usage","text":"<p>The aligned sequenced reads can be directly used for tasks that require read-level information, such as allele-specific expression or somatic variant analysis. The SGE matrix can also be analyzed with many software tools, such as Latent Dirichlet Allocation (LDA) and Seurat. </p> <p>An exemplary downstream analysis is provided at NovaScope-exemplary-downstream-analysis.</p>"},{"location":"getting_started/prep_input/","title":"Preparing Input","text":""},{"location":"getting_started/prep_input/#1-input-data","title":"1. Input Data","text":"<p>Begin by establishing a specific directory for your job. This directory will be used to organize the input configuration file (i.e., <code>config_job.yaml</code>, as outlined in 2. Prepare Input Config Files) and to store log files. </p> <p>The required input data includes 1st-seq and 2nd-seq FASTQ files, with the option to include an additional histology file and a file listing genes of interest. Below, we provide three examples from the same section chip, highlighting differences in 2nd-Seq library sequencing depth and selected regions.</p>"},{"location":"getting_started/prep_input/#example-1-regional-section-test-run","title":"Example 1 - Regional Section Test Run","text":"<p>The input data originates from a specific, limited region of a section chip, which was subjected to a relatively 2nd-Seq library sequencing depth. No histology files is provided.</p> <pre><code>smk_dir=\"&lt;path_to_NovaScope_repository&gt;\"    # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"$smk_dir/testrun/regional_section\"  \n\nmkdir -p  $job_dir &amp;&amp; cd $job_dir\n\nmkdir -p input_data \n</code></pre>"},{"location":"getting_started/prep_input/#example-2-full-section-shallow-sequencing-test-run","title":"Example 2 - Full Section Shallow Sequencing Test Run","text":"<p>The input data was derived from one section chip and features a relatively shallow 2nd-Seq library sequencing depth (approximately 163 million reads). A histology file is also accessible. </p> <pre><code>smk_dir=\"&lt;path_to_NovaScope_repository&gt;\"    # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"$smk_dir/testrun/full_section_shallow\"  \n\nmkdir -p  $job_dir &amp;&amp; cd $job_dir\n\n# Download the histology file\nwget https://historef-sample-data.s3.amazonaws.com/sample/b08c/histology.tif\n</code></pre>"},{"location":"getting_started/prep_input/#example-3-full-section-deep-sequencing-test-run","title":"Example 3 - Full Section Deep Sequencing Test Run","text":"<p>The input data is based on one section chip underwent deep sequencing, resulting in 2.61 billion reads, and this too comes with an available histology file.</p> <pre><code>smk_dir=\"&lt;path_to_NovaScope_repository&gt;\"    # Replace &lt;path_to_NovaScope_repository&gt; with the path to the NovaScope repository\njob_dir=\"$smk_dir/testrun/full_section_deep\"  \n\nmkdir -p  $job_dir &amp;&amp; cd $job_dir\n\n# Download the histology file\nwget https://historef-sample-data.s3.amazonaws.com/sample/b08c/histology.tif\n</code></pre>"},{"location":"getting_started/prep_input/#2-prepare-input-config-files","title":"2. Prepare Input Config Files","text":"<p>The pipeline necessitates a <code>config_job.yaml</code> file to define all inputs, outputs, and parameters. This <code>config_job.yaml</code> file should be provided in the <code>$job_dir</code>.</p> <p>Separate example <code>config_job.yaml</code> files for the regional section, full section shallow, and full section deep test runs are provided.  </p> <p>Below, you'll find explanations for each item specified in the <code>config_job.yaml</code>.</p>"},{"location":"getting_started/prep_input/#21-a-config-template","title":"2.1 A Config Template","text":"<pre><code>## ================================================\n##\n## Mandatory Fields:\n##\n## ================================================\n\n## Input\ninput:\n  flowcell: &lt;flowcell_id&gt;\n  section: &lt;section_chip_id&gt;\n  specie: &lt;specie_info&gt;\n  lane: &lt;lane_id&gt;                               ## Optional. Auto-assigned based on section's last letter if absent (A-&gt;1, B-&gt;2, C-&gt;3, D-&gt;4).\n  seq1st:\n    prefix: &lt;seq1st_id&gt;                         ## Optional. Defaults to \"L{lane}\" if absent.\n    fastq: &lt;path_to_seq1st_fastq_file&gt;\n    layout: &lt;path_to_sbcd_layout&gt;               ## Optional. See 2.2.\n  seq2nd:                                       ## See 2.2.\n    - prefix: &lt;seq2st_pair1_id&gt;\n      fastq_R1: &lt;path_to_seq2nd_pair1_fastq_Read1_file&gt;\n      fastq_R2: &lt;path_to_seq2nd_pair1_fastq_Read2_file&gt;\n    - prefix: &lt;seq2st_pair2_id&gt;\n      fastq_R1: &lt;path_to_seq2nd_pair2_fastq_Read1_file&gt;\n      fastq_R2: &lt;path_to_seq2nd_pair2_fastq_Read2_file&gt;\n    # ...\n  label: &lt;seq2nd_version&gt;                       ## Optional. A version label for the input seq2 data, if applicable.\n  histology: &lt;path_to_the_input_histology_file&gt; ## Optional.\n\n## Output\noutput: &lt;output_directory&gt;                      ## See 2.2.\nrequest:                                        ## See 2.2.\n  - &lt;required_output1&gt;\n  - &lt;required_output2&gt;\n  # ...\n\n## Environment\nenv_yml: &lt;path_to_config_env.yaml_file&gt;         ## If absent, the pipeline will check if a \"config_env.yaml\" file exists in the `info` subdirectory in the Novascope repository.\n\n## ================================================\n##\n##  Optional Fields:\n## \n##    The \"preprocess\" and \"histology\" parameters are included below, along side the default values.\n##    You only need to revise and enable the following parameters if you wish to utilize values different than the default.\n##\n## ================================================\n\n#preprocess:\n#  fastq2sbcd:\n#    format: DraI32\n#  sbcd2chip:\n#    gap_row: 0.0517\n#    gap_col: 0.0048\n#    dup_maxnum: 1\n#    dup_maxdist: 1\n#  smatch:\n#    skip_sbcd: 1            ## If absent, skip_sbcd can be calculated follows the fastq2sbcd format: 1 for DraI31 and 0 for DraI32.\n#    match_len: 27           ## Length of spatial barcode considered to be a perfect match.\n#  align:\n#    min_match_len: 30       ## A minimum number of matching bases.\n#    min_match_frac: 0.66    ## A minimum fraction of matching bases.\n#    len_sbcd: 30            ## Length of spatial barcode (in Read 1) to be copied to output FASTQ file (Read 1).\n#    len_umi: 9              ## Length of UMI barcode (in Read 2) to be copied to output FASTQ file (Read 1).\n#    len_r2: 101             ## Length of read 2 after trimming (including randomers).\n#    exist_action: overwrite ## Skip the action or overwrite the file if an intermediate or output file already exists. Options: \"skip\", and \"overwrite\".\n#    resource:               ## See 2.2.\n#      assign_type: stdin\n#      stdin:\n#        partition: standard\n#        threads: 10\n#        memory: 70000m\n#  dge2sdge:\n#    layout: null            ## If absent, the layout file in the info/assets/layout_per_section_basis/layout.1x1.tsv will be used for RGB plots.\n#  gene_visual: null         ## If you have a specific set of genes to visualize, specify the path to a file containing a list of gene names (one per line) here. By default, the top five genes with the highest expression are visualized.\n#  visualization:\n#    drawxy:\n#      coord_per_pixel: 1000\n#      intensity_per_obs: 50\n#      icol_x: 3\n#      icol_y: 4\n#\n#histology:\n#    resolution: 10\n#    figtype: \"hne\"          ## Options: \"hne\", \"dapi\", and \"fl\".\n</code></pre>"},{"location":"getting_started/prep_input/#22-additional-information","title":"2.2 Additional Information","text":""},{"location":"getting_started/prep_input/#input","title":"Input","text":"<p><code>seq1st</code> </p> <p><code>prefix</code></p> <p>The <code>prefix</code> will be used to organize the 1st-seq FASTQ files. Make sure the <code>prefix</code> parameter in the corresponding flowcell is unique.  </p> <p><code>layout</code></p> <p>A file to provide the layout of tiles in a section chip with the following format. If absent, NovaScope will automatically look for the sbcd layout within the NovaScope repository at info/assets/layout_per_tile_basis, using the section chip ID for reference.</p> <pre><code>lane  tile  row  col  rowshift  colshift\n3     2556  1    1    0         0\n3     2456  2    1    0         0.1715\n</code></pre> <ul> <li>lane: Lane IDs</li> <li>tile: Tile IDs </li> <li>row &amp; col: The layout position</li> <li>rowshift &amp; colshift: The gap information</li> </ul> <p><code>seq2nd</code></p> <p>Every FASTQ pair associated with the input section chip should be supplied in <code>seq2nd</code>.  The <code>prefix</code> should be unique among all 2nd-seq FASTQ pairs, not just within this flowcell.</p>"},{"location":"getting_started/prep_input/#output","title":"output","text":"<p>The output directory will be used to organize the input files and store output files. Please see the structure directory here</p>"},{"location":"getting_started/prep_input/#request","title":"request:","text":"<p>The pipeline interprets the requested output files via this parameter and determines which jobs need to be executed. </p> <p>Simply define the final output required, and all intermediary files contributing to this output will be automatically generated (i.e.,  the dependencies between rules). For instance, outputs from <code>\"sbcd-per-flowcell\"</code> serve as inputs for <code>\"sbcd-per-section\"</code>. Thus, by requesting <code>\"sbcd-per-section\"</code>, the pipeline will generate not only the files for <code>\"sbcd-per-section\"</code> but also those for <code>\"sbcd-per-flowcell\"</code>. For detailed insights into these dependencies, please consult the rulegraph.</p> <p>The options and corresponding output files are listed below:</p> <ul> <li><code>\"sbcd-per-flowcell\"</code>: A spatial barcode map for a flowcell organzied on a per-tile basis. Each tile has a compressed tab-delimited file for barcodes and corresponding local coordinates in the tile.</li> <li><code>\"sbcd-per-section\"</code>: A spatial barcode map for a section chip, including a compressed tab-delimited file for barcodes and corresponding global coordinates in the section chip, and an image displaying the spatial distribution of the barcodes' coordinates.</li> <li><code>\"smatch-per-section\"</code>: A compressed tab-delimited file with spatial barcodes corresponding to the 2nd-seq reads, a \"smatch\" image depicting the distribution of spatial coordinates for the matching barcodes, and a summary file of the matching results. </li> <li><code>\"align-per-section\"</code>: A BAM file accompanied by alignment summary metrics, along with spatial digital gene expression (sDGE) matrices for Gene, GeneFull, splice junctions (SJ), and Velocyto.</li> <li><code>\"sge-per-section\"</code>: An sDGE matrix, an \"sge\" image depicting the spatial alignment of transcripts, and an RGB image representing the sDGE matrix and selected genes. In the absence of specified genes of interest, the RGB image will display the top 5 genes with the highest expression levels.</li> <li><code>\"hist-per-section\"</code>: Two aligned histology files, one of which is a referenced geotiff file facilitating the coordinate transformation between the SGE matrix and the histology image. The other is a tiff file matching the dimensions of both the \"smatch\" and \"sge\" images.</li> </ul>"},{"location":"getting_started/prep_input/#preprocess","title":"preprocess","text":"<p><code>align</code></p> <p><code>resource</code>: </p> <p>The <code>resource</code> parameters are only applicable for HPC users. The <code>assign_type</code> include two options: <code>\"stdin\"</code> (recommended) and <code>\"filesize\"</code>. </p> <p>If using <code>\"stdin\"</code>, define the resource parameters in the <code>stdin</code>, including <code>partition</code>, <code>threads</code>, and <code>memory</code>, to fit your case. Such resource will be used for the align step. An example is provided below. </p> <pre><code>preprocess:\n#  ...\n  align:\n#    ...\n    resource:\n      assign_type: stdin\n      stdin:\n        partition: standard\n        threads: 10\n        memory: 70000m\n</code></pre> <p>If using <code>\"filesize\"</code>, ensure to include details about the computing capabilities of all available nodes. This includes the partition name, the available number of CPUs, and the memory allocated per CPU (refer to the example provided). Resource allocation will be automatically adjusted based on the total size of the input 2nd-seq FASTQ files and the available computing resources. The preliminary strategy for resource allocation is as follows: for input 2nd-seq FASTQ files smaller than 200GB, allocate 70GB of memory for alignment processes; for file sizes ranging from 200GB to 400GB, allocate 140GB of memory; for anything larger, 330GB of memory will be designated for alignment step.</p> <pre><code>preprocess:\n#  ...\n  align:\n#    ...\n    resource:\n      assign_type: filesize\n      filesize:\n        - partition: standard\n          max_n_cpus: 20\n          mem_per_cpu: 7g\n        - partition: largemem\n          max_n_cpus: 10\n          mem_per_cpu: 25g\n</code></pre>"},{"location":"installation/env_setup/","title":"Setup A Environment YAML File","text":"<p>Create a <code>config_env.yaml</code> file for the environment setup, see our example here.</p> <p>Below is a brief description of all the items in the YAML file. Replace the placeholders with your specific input variables to customize it according to your needs, and provide it via your <code>config_job.yaml</code>.</p>"},{"location":"installation/env_setup/#tools","title":"Tools","text":"<p>For tools that are not explicitly defined, the pipeline will automatically check if they are installed and include them in the system path for use. This allows the pipeline to utilize these tools without needing manual configuration for each one.</p> <pre><code>tools:\n  spatula: &lt;path_to_the_spatula_bin_file&gt;       ## Default: \"spatula\"\n  samtools: &lt;path_to_the_samtools_bin_file&gt;     ## Default: \"samtools\"\n  star: &lt;path_to_the_starsolo_bin_file&gt;           ## Default: \"STAR\"\n</code></pre>"},{"location":"installation/env_setup/#hpc-specific-configuration","title":"HPC-specific Configuration:","text":"<p>For HPC users, use the <code>envmodules</code> section to load the required software tools as modules. If a tool is not listed in the envmodules section, the pipeline will assume it's installed system-wide. For local executions, you may remove this section if running the pipeline on your local machine.</p> <p>Please specify the version information. </p> <pre><code>envmodules:\n  python: \"python/&lt;version_information&gt;\"\n  gcc: \"gcc/&lt;version_information&gt;\"\n  gdal: \"gdal/&lt;version_information&gt;\"\n  imagemagick: \"imagemagick/&lt;version_information&gt;\"\n  #Bioinformatics: \"Bioinformatics\"\n  #samtools: \"samtools/1.13-fwwss5n\"\n</code></pre> <ul> <li><code>python</code>: If your python environment was set up using a Python version accessed through a module, your environment depends on certain shared files from that module. Therefore, you must add the <code>python: \"python/&lt;version_information&gt;\"</code>  in the <code>envmodules</code> section to load the same module you initially used to establish your environment. But if you set up with a locally installed Python (not using <code>module load</code>), comment out or remove the module line <code>python: \"python/&lt;version_information&gt;\"</code>.</li> <li><code>Bioinformatics</code> and <code>samtools</code>: It is also feasible to use <code>envmodules</code> to load samtools instead of defining its path in <code>tools</code>.</li> </ul>"},{"location":"installation/env_setup/#reference-database","title":"Reference Database","text":"<p>Please list every reference database used for alignment here. The reference data are provided via . TODO: add the download link</p> <p>Please Ensure the reference database corresponds to the species of your input data. </p> <pre><code>ref:\n  align:\n    &lt;specie1&gt;: &lt;path_to_the_reference_genome_index_for_specie1&gt;\n    &lt;specie2&gt;: &lt;path_to_the_reference_genome_index_for_specie2&gt;\n   #...\n</code></pre>"},{"location":"installation/env_setup/#python-environment","title":"Python Environment","text":"<pre><code>pyenv: &lt;path_to_the_python_environment1&gt;\n</code></pre>"},{"location":"installation/requirement/","title":"1. Software Installation","text":""},{"location":"installation/requirement/#11-novascope","title":"1.1 NovaScope.","text":"<pre><code>git clone git@github.com:seqscope/NovaScope.git\n</code></pre>"},{"location":"installation/requirement/#12-snakemake","title":"1.2 Snakemake","text":"<p>Snakemake orchestrates the workflow of this pipeline. We recommend installing Snakemake using Conda or Mamba. For detailed installation instructions, please refer to the official Snakemake documentation.</p> <p>The NovaScope is created and tested using Snakemake v7.29.0 and v8.6.0.</p>"},{"location":"installation/requirement/#13-other-dependent-software-tools","title":"1.3 Other Dependent Software Tools","text":"<p>The dependent software tools are listed below. The versions specified for each software tool have been verified for compatibility with our pipeline, though other versions may also be compatible.</p> <pre><code>* STAR (v2.7.11a)\n* Samtools (v1.14 and v1.19)\n* spatula \n* Python (v3.9.12, v3.10, and v3.12.2)\n* imagemagick (7.1.0-25.lua and 7.1.1-30)\n* gcc (v10.3.0) \n* gdal (v3.5.1)\n</code></pre> <p>We provide an example work log documenting the installation of the aforementioned software tools.</p>"},{"location":"installation/requirement/#2-reference-datasets","title":"2. Reference Datasets","text":"<p>Please download the necessary reference datasets for STARsolo alignment. The versions listed below are those we utilized in our setup.</p> <pre><code>* mouse: mm39\n* human: GRCh38\n* rat: mRatBN7\n* worm: WBcel235\n</code></pre>"},{"location":"installation/requirement/#3-configure-python-environment","title":"3. Configure Python Environment","text":"<p>If you already have an existing Python environment with all required packages (see pyenv_req.txt), skip 3.1.</p>"},{"location":"installation/requirement/#31-create-a-new-python-environment","title":"3.1 Create a New Python Environment","text":"<pre><code>pyenv_dir=&lt;directory_of_python_environment&gt;\npyenv_name=&lt;name_of_python_environment&gt;\nsmk_dir=&lt;path_to_NovaScope_repository&gt;\n\nmkdir -p $pyenv_dir\ncd $pyenv_dir\n\npython -m venv $pyenv_name\nsource $pyenv_name/bin/activate\npip install -r $smk_dir/installation/pyenv_req.txt\n</code></pre>"},{"location":"installation/requirement/#32-install-the-historef-package-using-the-whl-file","title":"3.2 Install the historef Package Using the whl File","text":"<p>Below are codes to download historef's latest version at document creation. To access the most recent version, please see its GitHub repository.</p> <pre><code>source $pyenv_dir/$pyenv_name/bin/activate\nwget -P $smk_dir/installation https://github.com/seqscope/historef/releases/download/v0.1.1/historef-0.1.1-py3-none-any.whl\npip install $smk_dir/installation/historef-0.1.1-py3-none-any.whl\n</code></pre>"},{"location":"installation/slurm/","title":"Snakemake with SLURM","text":"<p>It is recommended to integrate SLURM scheduler with Snakemake, which can automate the process of submitting your jobs.</p> <p>Please be aware that Snakemake introduced significant updates for cluster Configuration starting from version 8. Thus, we advise checking to verify your Snakemake version using <code>snakemake --version</code>. </p> <p>In NovaScope, we utilized a cluster configuration profile to define the details of the cluster and resources given its consistency and time-saving benefits. More details are provided below. Those files were crafted with inspiration from the smk-simple-slurm repository.</p>"},{"location":"installation/slurm/#a-cluster-configuration-file-for-snakemake-v7290","title":"A Cluster Configuration file for Snakemake v7.29.0","text":"<p>Create a <code>config.yaml</code> with the following settings. Please substitute the placeholders below, marked with &lt;&gt;, to suit your specific case. Please see our example file at slurm/v7.29.0/config.yaml. </p> <pre><code>## Cluster Configuration\n## The following setting also aids in organizing log files by creating rule-specific subdirectories within the job's log directory, each holding its own output and error files.\ncluster:\n  mkdir -p logs/{rule}/ &amp;&amp;\n  sbatch\n    --job-name={rule}_{wildcards}\n    --output=logs/{rule}/{rule}___{wildcards}___%j.out\n    --error=logs/{rule}/{rule}___{wildcards}___%j.err\n    --account={resources.account}\n    --partition={resources.partition}\n    --mem={resources.mem}\n    --time={resources.time}\n    --cpus-per-task={threads}\n    --parsable\n    --nodes={resources.nodes}\n\n## Default Resources for Jobs\ndefault-resources:\n  - partition=&lt;your_default_partition&gt;    # Replace &lt;your_default_partition&gt; with your actual partition name\n  - mem=&lt;default_memory_allocation&gt;       # Replace &lt;default_memory_allocation&gt; with memory, e.g., \"4G\"\n  - time=&lt;default_time_limit&gt;             # Replace &lt;default_time_limit&gt; with time, e.g., \"01:00:00\"\n  - nodes=&lt;default_number_of_nodes&gt;       # Replace &lt;default_number_of_nodes&gt; with nodes, e.g., \"1\"\n  - account=&lt;default_account_information&gt; # Replace &lt;default_account_information&gt; with your account info\n\n## General Snakemake Settings\njobs: &lt;max_number_of_jobs&gt;               # Replace &lt;max_number_of_jobs&gt; with your desired maximum number of concurrent jobs, e.g., 10\nlatency-wait: &lt;latency_seconds&gt;          # Replace &lt;latency_seconds&gt; with the number of seconds to wait if job output is not present, e.g., 120\nlocal-cores: &lt;local_core_count&gt;          # Replace &lt;local_core_count&gt; with the max number of cores to use locally, e.g., \"20\"\nrestart-times: &lt;restart_attempts&gt;        # Replace &lt;restart_attempts&gt; with the number of times to retry failing jobs, e.g., \"0\" for no retries\nmax-jobs-per-second: &lt;job_submission_rate&gt; # Replace &lt;job_submission_rate&gt; with the limit on how many jobs can be submitted per second, e.g., \"20\"\nkeep-going: &lt;continue_after_failure&gt;     # Replace &lt;continue_after_failure&gt; with True or False to indicate whether to continue executing other jobs after a failure\nrerun-incomplete: &lt;rerun_incomplete_jobs&gt; # Replace &lt;rerun_incomplete_jobs&gt; with True or False to decide if incomplete jobs should be rerun\nprintshellcmds: &lt;print_commands&gt;         # Replace &lt;print_commands&gt; with True or False to specify if shell commands should be printed before execution\n\n## Scheduler Settings\n#scheduler: greedy      \n\n## Conda Environment Settings\nuse-conda: &lt;True_or_False&gt;               # Enable use of Conda environments\nconda-frontend: conda                    # Specify Conda as the package manager frontend\n</code></pre>"},{"location":"installation/slurm/#a-cluster-configuration-file-for-snakemake-v860","title":"A Cluster Configuration file for Snakemake v8.6.0","text":"<p>Please first install the Snakemake executor plugin \"cluster-generic\":</p> <pre><code>pip install snakemake-executor-plugin-cluster-generic\n</code></pre> <p>Then, create the cluster configuration file with below. Please substitute the placeholders below, marked with &lt;&gt;, to suit your specific case. Please see our example file at slurm/v8.6.0/config.yaml. </p> <pre><code>executor: \"cluster-generic\"\ncluster-generic-submit-cmd: \"mkdir -p logs/{rule}/ &amp;&amp;\n  sbatch\n    --job-name={rule}_{wildcards} \\\n    --output=logs/{rule}/{rule}___{wildcards}___%j.out \\\n    --error=logs/{rule}/{rule}___{wildcards}___%j.err \\\n    --partition={resources.partition} \\\n    --mem={resources.mem} \\\n    --time={resources.time} \\\n    --cpus-per-task={threads} \\\n    --parsable \\\n    --nodes={resources.nodes} \"\n\ndefault-resources:\n  - partition=\"main\"\n  - mem=\"6500MB\"\n  - time=\"05:00:00\"\n  - nodes=1\n\n\njobs: 10                       \nlatency-wait: 120              \nlocal-cores: 20                \nrestart-times: 0               \nmax-jobs-per-second: 20\nkeep-going: True\nrerun-incomplete: True\nprintshellcmds: True\n\nsoftware-deployment-method: conda\n</code></pre>"},{"location":"installation/slurm/#additional-functions","title":"Additional functions","text":"<p>If you encounter situations where your jobs fail without any warnings, it is feasible to using a cluster status script to keep track of your jobs. See details here.</p>"}]}